{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Music Recommendation System\n",
    "\n",
    "## Description\n",
    "\n",
    "This project is a study on the music app,Spotify. Spotify is in the top spot because of Big Data Analytics. Due to its enormous playlist and its discovery weekly suggestion. This study creates a recommender system that will recommend new musical artists to a user based on their listening history.To build our recommendation system we will be using Spark and the collaborative filtering technique.\n",
    "\n",
    "### Why Spark?\n",
    "\n",
    "As industries evelop and the products and services becoming more creative and  customer-based, the need for machine learning algorithms to help develop personalizations, recommendations, and predictive insights becomes much more essential. Apache Spark involves graph computation, streaming, and real-time interactive query processing to solve highly complex machine learning problems.\n",
    "\n",
    "Furthermore, Apache Spark is a fast and general-purpose cluster computing system. It is also simple, highly scalable, and effectively integrable with other tools, like R, SQL, Python, Scala, and Java.\n",
    "\n",
    "\n",
    "## Datasets\n",
    "\n",
    "The dataset for this project is publicly available song data from audioscrobbler. However, we modified the original data files so that the code will run in a reasonable time on a single machine. The reduced data files can be found [here](http://www-etud.iro.umontreal.ca/~bergstrj/audioscrobbler_data.html) and contains only the information relevant to the top 50 most prolific users (highest artist play counts).\n",
    "\n",
    "The original data file `user_artist_data.txt` contained about 141,000 unique users, and 1.6 million unique artists. About 24.2 million usersâ€™ plays of artists are recorded, along with their count.\n",
    "\n",
    "Also note that the data set includes `artist_alias.txt`, which maps artist IDs that are known misspellings or variants to the canonical ID of that artist.\n",
    "\n",
    "The `artist_data.txt` file then provides a map from the canonical artist ID to the name of the artist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the three datasets into RDDs and name them `artistData`, `artistAlias`, and `userArtistData`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import *\n",
    "import random\n",
    "from operator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(s, delimeters=\" \", to_int=None):\n",
    "    s = s.split(delimeters)\n",
    "    if to_int:\n",
    "        return tuple([int(s[i]) if i in to_int else s[i] for i in range(len(s))])\n",
    "    return tuple(s)\n",
    "artistData = sc.textFile(\"artist_data_small.txt\").map(lambda x: parser(x,'\\t',[0]))\n",
    "artistAlias = sc.textFile(\"artist_alias_small.txt\").map(lambda x: parser(x,'\\t', [0,1]))\n",
    "artistAliasMap = artistAlias.collectAsMap()\n",
    "userArtistData = sc.textFile(\"user_artist_data_small.txt\").map(lambda x: parser(x,' ',[0,1,2]))\n",
    "userArtistData = userArtistData.map(lambda x: (x[0], artistAliasMap.get(x[1], x[1]), x[2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "The code below, detects the three users with the highest number of total play counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 1059637 has a total play count of 674412 and a mean play count of 1878.5849582172702.\n",
      "User 2064012 has a total play count of 548427 and a mean play count of 9455.637931034482.\n",
      "User 2069337 has a total play count of 393515 and a mean play count of 1519.3629343629343.\n"
     ]
    }
   ],
   "source": [
    "def summary(user_id):\n",
    "    play_list = userArtistData.map(lambda x: (x[0], (x[1], x[2]))).lookup(user_id)\n",
    "    total = sum(x[1] for x in play_list)\n",
    "    print (\"User %s has a total play count of %s and a mean play count of %s.\" % (user_id, total, total/len(play_list),))\n",
    "summary(1059637)\n",
    "summary(2064012)\n",
    "summary(2069337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Splitting Data for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1059637, 1000049, 1), (1059637, 1000056, 1), (1059637, 1000114, 2)]\n",
      "[(1059637, 1000010, 238), (1059637, 1000062, 11), (1059637, 1000123, 2)]\n",
      "[(1059637, 1000094, 1), (1059637, 1000112, 423), (1059637, 1000113, 5)]\n",
      "19769\n",
      "19690\n",
      "10022\n"
     ]
    }
   ],
   "source": [
    "trainingData, validationData, testData = userArtistData.randomSplit([40,40,20], 13)\n",
    "trainingData.cache()\n",
    "validationData.cache()\n",
    "testData.cache()\n",
    "print (trainingData.take(3))\n",
    "print (validationData.take(3))\n",
    "print (testData.take(3))\n",
    "print (trainingData.count())\n",
    "print (validationData.count())\n",
    "print (testData.count())\n",
    "# validationSet.lookup(1073421)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Recommender Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "\n",
    "def cal_score(predict, actual):\n",
    "    if len(actual) < len(predict):\n",
    "#         print \"here\"\n",
    "        predict = predict[0:len(actual)]\n",
    "    return len(list(set(predict) & set(actual)))*1.0/len(actual)\n",
    "\n",
    "def modelEval(model, dataset):\n",
    "    # Find the list of all artists in the whole data set\n",
    "    all_artists = userArtistData.map(lambda x: x[1]).distinct().collect()\n",
    "    # Find the users in the input dataset\n",
    "    test_user = dataset.map(lambda p: p[0]).distinct().collect()\n",
    "    # Find the artists each user listened to in the training set and generate the test data\n",
    "    global trainingData\n",
    "    testdata = trainingData.filter(lambda x: x[0] in test_user).map(lambda x: (x[0], x[1])).groupByKey()\n",
    "    testdata = testdata.map(lambda x: (x[0], list(x[1])))\n",
    "    testdata = testdata.flatMap(lambda x: [(x[0],a) for a in all_artists if a not in x[1]])\n",
    "    # Find the artists each user listened to in the input dataset\n",
    "    testdata_actual = dataset.map(lambda x: (x[0], x[1])).groupByKey().map(lambda x: (x[0], list(x[1]))).collectAsMap()\n",
    "    predictions = model.predictAll(testdata).map(lambda x: (x[0], (x[1], x[2])))\n",
    "    predictions = predictions.groupByKey().map(lambda x: (x[0], sorted(list(x[1]), key=lambda y: y[1], reverse=True)))\n",
    "    predictions = predictions.map(lambda x: (x[0], cal_score([y[0] for y in x[1]], testdata_actual[x[0]])))\n",
    "    return predictions.map(lambda x:x[1]).reduce(lambda x, y: x+ y) * 1.0 / len(test_user)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Construction\n",
    "\n",
    "Now we can build the best model possibly using the validation set of data and the `modelEval` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model score for rank 2 is 0.08993238201906095\n",
      "The model score for rank 10 is 0.0905379417355099\n",
      "The model score for rank 20 is 0.08352965938288216\n"
     ]
    }
   ],
   "source": [
    "training = trainingData.map(lambda x: Rating(int(x[0]), int(x[1]), float(x[2])))\n",
    "for r in [2, 10, 20]:\n",
    "    model = ALS.trainImplicit(training, rank = r, seed=345)\n",
    "    print (\"The model score for rank %s is %s\" % (r, modelEval(model, validationData)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using the bestModel, we will check the results over the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06028154355485623\n"
     ]
    }
   ],
   "source": [
    "bestModel = ALS.trainImplicit(training, rank=10, seed=345)\n",
    "print (modelEval(bestModel, testData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artist Recommendations\n",
    "Predicting the Top 10 Artists for user '1059637'. To achieve this we used the above model and the recommendProducts function.Further, we Map the results (integer IDs) into the real artist name using artistAlias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist 0: Something Corporate\n",
      "Artist 1: My Chemical Romance\n",
      "Artist 2: Counting Crows\n",
      "Artist 3: U2\n",
      "Artist 4: Green Day\n",
      "Artist 5: Further Seems Forever\n",
      "Artist 6: Alkaline Trio\n",
      "Artist 7: Switchfoot\n",
      "Artist 8: Underoath\n",
      "Artist 9: Smash Mouth\n"
     ]
    }
   ],
   "source": [
    "recommended = map(lambda x: x.product, bestModel.recommendProducts(1059637, 10))\n",
    "for i, artist in enumerate(recommended):\n",
    "    print (\"Artist %s: %s\" % (i, artistData.lookup(artist)[0],))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
